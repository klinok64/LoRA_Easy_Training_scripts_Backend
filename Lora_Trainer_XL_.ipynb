{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# üåü XL Lora Trainer by Hollowstrawberry (Kaggle Edition)\n",
        "\n",
        "Kaggle GPU Notebook —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è.  –ò–¥–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —ç—Ç–æ –±—É–¥–µ—Ç –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ.\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ —Å—Ç–∞–ª –≤–æ–∑–º–æ–∂–µ–Ω –±–ª–∞–≥–æ–¥–∞—Ä—è –æ—Ç–∫—Ä—ã—Ç–æ–º—É –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–æ–¥—É –æ—Ç —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã—Ö –ª—é–¥–µ–π:\n",
        "* [kohya-ss](https://github.com/kohya-ss/sd-scripts)\n",
        "* [derrian-distro](https://github.com/derrian-distro/LoRA_Easy_Training_scripts_Backend/)\n",
        "* [Linaqruf](https://github.com/Linaqruf/kohya-trainer)\n",
        "* [Jelosus2](https://github.com/Jelosus2/LoRA_Easy_Training_Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8clWTZEu-g"
      },
      "source": [
        "### ‚≠ï Disclaimer\n",
        "–¶–µ–ª—å —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ - –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ—á—Ç–∏—Ç–µ –∏ —Å–æ–±–ª—é–¥–∞–π—Ç–µ [–ü—Ä–∞–≤–∏–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Kaggle](https://www.kaggle.com/legal/terms) –∏ –∏—Ö [–£—Å–ª–æ–≤–∏—è –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è](https://www.kaggle.com/legal/terms)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPQlB4djNm3C"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| üè† **Homepage** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| üåü **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| üåü **Legacy XL Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OglZzI_ujZq-",
        "outputId": "85d43cab-b903-45e1-f43a-16405e37570e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import toml\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# These carry information from past executions\n",
        "if \"model_url\" in globals():\n",
        "  old_model_url = model_url\n",
        "else:\n",
        "  old_model_url = None\n",
        "if \"dependencies_installed\" not in globals():\n",
        "  dependencies_installed = False\n",
        "if \"model_file\" not in globals():\n",
        "  model_file = None\n",
        "\n",
        "# These may be set by other cells, some are legacy\n",
        "if \"custom_dataset\" not in globals():\n",
        "  custom_dataset = None\n",
        "if \"override_dataset_config_file\" not in globals():\n",
        "  override_dataset_config_file = None\n",
        "if \"continue_from_lora\" not in globals():\n",
        "  continue_from_lora = \"\"\n",
        "if \"override_config_file\" not in globals():\n",
        "  override_config_file = None\n",
        "\n",
        "#try:\n",
        "#  LOWRAM = int(next(line.split()[1] for line in open('/proc/meminfo') if \"MemTotal\" in line)) / (1024**2) < 15\n",
        "#except:\n",
        "#  LOWRAM = True\n",
        "\n",
        "LOWRAM = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "BETTER_EPOCH_NAMES = True\n",
        "FIX_DIFFUSERS = True\n",
        "\n",
        "\n",
        "#@title ## üö© Start Here\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Setup\n",
        "#@markdown –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –±—É–¥–µ—Ç —Ç–∞–∫–∏–º –∂–µ, –∫–∞–∫ –∏ –ø–∞–ø–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è –≤–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ–±–µ–ª—ã –Ω–µ –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è.\n",
        "project_name = \"hypnohub512\" #@param {type:\"string\"}\n",
        "project_name = project_name.strip()\n",
        "#@markdown –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –Ω–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–µ—Ç–µ –æ–¥–Ω—É –∏ —Ç—É –∂–µ. –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º.\n",
        "folder_structure = \"Organize by project (MyDrive/Loras/project_name/dataset)\" #@param [\"Organize by category (MyDrive/lora_training/datasets/project_name)\", \"Organize by project (MyDrive/Loras/project_name/dataset)\"]\n",
        "#@markdown –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –í—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é, –≤—Å—Ç–∞–≤–∏–≤ —Å—Å—ã–ª–∫—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–ª–∏ —Ñ–∞–π–ª –≤ –≤–∞—à–µ–º Google Drive, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å `/content/drive/MyDrive`. **–í Kaggle, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.**\n",
        "training_model = \"Illustrious XL 0.1\" #@param [\"Pony Diffusion V6 XL\", \"Illustrious XL 0.1\", \"NoobAI V-Pred 1.0\", \"NoobAI Eps 1.1\", \"Animagine XL V3\", \"Stable Diffusion XL 1.0 base\"]\n",
        "optional_custom_training_model = \"\" #@param {type:\"string\"}\n",
        "custom_model_is_diffusers = False #@param {type:\"boolean\"}\n",
        "custom_model_is_vpred = False #@param {type:\"boolean\"}\n",
        "#@markdown –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ wandb, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤–∞—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏.\n",
        "wandb_key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "load_diffusers = custom_model_is_diffusers and len(optional_custom_training_model) > 0\n",
        "vpred = custom_model_is_vpred and len(optional_custom_training_model) > 0\n",
        "\n",
        "if optional_custom_training_model:\n",
        "  model_url = optional_custom_training_model\n",
        "elif \"Pony\" in training_model:\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/hollowstrawberry/67AB2F\"\n",
        "  else:\n",
        "    model_url = \"https://civitai.com/api/download/models/290640\"\n",
        "    model_file = \"/content/ponyDiffusionV6XL.safetensors\"\n",
        "elif \"Animagine\" in training_model:\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.0\"\n",
        "  else:\n",
        "    model_url = \"https://civitai.com/api/download/models/293564\"\n",
        "    model_file = \"/content/animagineXLV3.safetensors\"\n",
        "elif \"Illustrious\" in training_model:\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0\"\n",
        "  else:\n",
        "    model_url = \"https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0/resolve/main/Illustrious-XL-v0.1.safetensors\"\n",
        "elif \"NoobAI Eps\" in training_model:\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/Laxhar/noobai-XL-1.1\"\n",
        "  else:\n",
        "    model_url = \"https://huggingface.co/Laxhar/noobai-XL-1.1/resolve/main/NoobAI-XL-v1.1.safetensors\"\n",
        "elif \"NoobAI V-Pred\" in training_model:\n",
        "  vpred = True\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/Laxhar/noobai-XL-Vpred-1.0\"\n",
        "  else:\n",
        "    model_url = \"https://huggingface.co/Laxhar/noobai-XL-Vpred-1.0/resolve/main/NoobAI-XL-Vpred-v1.0.safetensors\"\n",
        "else:\n",
        "  if load_diffusers:\n",
        "    model_url = \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "  else:\n",
        "    model_url = \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\"\n",
        "\n",
        "if load_diffusers:\n",
        "  vae_file = \"stabilityai/sdxl-vae\"\n",
        "else:\n",
        "  vae_url = \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\"\n",
        "  vae_file = \"/content/sdxl_vae.safetensors\"\n",
        "\n",
        "model_url = model_url.strip()\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Processing\n",
        "resolution = 512 #@param {type:\"slider\", min:512, max:1536, step:128}\n",
        "caption_extension = \".txt\" #@param [\".txt\", \".caption\"]\n",
        "#@markdown –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –∞–Ω–∏–º–µ-—Ç–µ–≥–æ–≤ –Ω–∞ –º–µ—Å—Ç–µ —É–ª—É—á—à–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏. –¢–µ–≥ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏–¥–µ—Ç –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –Ω–µ –±—É–¥–µ—Ç –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å—Å—è.<p>\n",
        "shuffle_tags = True #@param {type:\"boolean\"}\n",
        "shuffle_caption = shuffle_tags\n",
        "activation_tags = \"0\" #@param [0,1,2,3]\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Steps <p>\n",
        "#@markdown –í–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –Ø —Ä–µ–∫–æ–º–µ–Ω–¥—É—é, —á—Ç–æ–±—ã –≤–∞—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —É–º–Ω–æ–∂–µ–Ω–Ω—ã–µ –Ω–∞ –∏—Ö –ø–æ–≤—Ç–æ—Ä—ã, —Å–æ—Å—Ç–∞–≤–ª—è–ª–∏ –æ–∫–æ–ª–æ 100, –∏–ª–∏ 1 –ø–æ–≤—Ç–æ—Ä —Å –±–æ–ª–µ–µ —á–µ–º 100 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.\n",
        "num_repeats = 1 #@param {type:\"number\"}\n",
        "#@markdown –í—ã–±–µ—Ä–∏—Ç–µ, –∫–∞–∫ –¥–æ–ª–≥–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ–±—É—á–∞—Ç—å. –•–æ—Ä–æ—à–∞—è –æ—Ç–ø—Ä–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ - –æ–∫–æ–ª–æ 10 —ç–ø–æ—Ö –∏–ª–∏ –æ–∫–æ–ª–æ 2000 —à–∞–≥–æ–≤.<p>\n",
        "#@markdown –û–¥–Ω–∞ —ç–ø–æ—Ö–∞ - —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤, —Ä–∞–≤–Ω–æ–µ: –≤–∞—à–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —É–º–Ω–æ–∂–µ–Ω–Ω–æ–º—É –Ω–∞ –∏—Ö –ø–æ–≤—Ç–æ—Ä—ã, –¥–µ–ª–µ–Ω–Ω–æ–º—É –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞. <p>\n",
        "preferred_unit = \"Epochs\" #@param [\"Epochs\", \"Steps\"]\n",
        "how_many = 4 #@param {type:\"number\"}\n",
        "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
        "#@markdown –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö –ø–æ–∑–≤–æ–ª–∏—Ç –≤–∞–º –ª—É—á—à–µ —Å—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤–∞—à–µ–π LoRA.\n",
        "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
        "save_every_n_steps = 100 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "keep_only_last_n_epochs = 10 #@param {type:\"number\"}\n",
        "if not save_every_n_epochs:\n",
        "  save_every_n_epochs = max_train_epochs\n",
        "if not keep_only_last_n_epochs:\n",
        "  keep_only_last_n_epochs = max_train_epochs\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Learning\n",
        "#@markdown –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω–æ–π –¥–ª—è –≤–∞—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ï—Å–ª–∏ –≤–∞—à–∞ LoRA –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —á–µ—Ä–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —É–º–µ–Ω—å—à–∏—Ç–µ unet –∏ text encoder –¥–æ 1e-4 –∏ 1e-5 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –∏–ª–∏ –¥–∞–∂–µ –Ω–∏–∂–µ. <p>\n",
        "#@markdown –ï—Å–ª–∏ –≤—ã –æ–±—É—á–∞–µ—Ç–µ —Å—Ç–∏–ª—å, –≤—ã –º–æ–∂–µ—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å text encoder –Ω–∞ 0.\n",
        "unet_lr = 3e-4 #@param {type:\"number\"}\n",
        "text_encoder_lr = 6e-5 #@param {type:\"number\"}\n",
        "#@markdown –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ - —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è. –ï—Å–ª–∏ –≤—ã –Ω–µ —É–≤–µ—Ä–µ–Ω—ã, –≤—ã–±–µ—Ä–∏—Ç–µ `constant` –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–π—Ç–µ —á–∏—Å–ª–æ. –Ø –ª–∏—á–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é `cosine_with_restarts` —Å 3 –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏.\n",
        "lr_scheduler = \"rex\" #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\", \"rex\"]\n",
        "lr_scheduler_number = 3 #@param {type:\"number\"}\n",
        "#@markdown –®–∞–≥–∏, –ø–æ—Ç—Ä–∞—á–µ–Ω–Ω—ã–µ –Ω–∞ \"—Ä–∞–∑–æ–≥—Ä–µ–≤\" —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –Ø —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ—Å—Ç–∞–≤–∏—Ç—å 5%.\n",
        "lr_warmup_ratio = 0.05 #@param {type:\"slider\", min:0.0, max:0.2, step:0.01}\n",
        "lr_warmup_steps = 0\n",
        "#@markdown –≠—Ç–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–≥—É—Ç –¥–∞—Ç—å –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. min_snr_gamma —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç –ø–æ—Ç–µ—Ä–∏ —Å —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏. ip_noise_gamma —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º.\n",
        "min_snr_gamma_enabled = False #@param {type:\"boolean\"}\n",
        "min_snr_gamma = 8.0 #@param {type:\"slider\", min:4, max:16.0, step:0.5}\n",
        "ip_noise_gamma_enabled = True #@param {type:\"boolean\"}\n",
        "ip_noise_gamma = 0.1 #@param {type:\"slider\", min:0.05, max:0.1, step:0.01}\n",
        "#@markdown Multinoise –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å —Å —Ü–≤–µ—Ç–æ–≤—ã–º –±–∞–ª–∞–Ω—Å–æ–º (–±–æ–ª–µ–µ —Ç–µ–º–Ω—ã–µ —Ç–µ–º–Ω—ã–µ, –±–æ–ª–µ–µ —Å–≤–µ—Ç–ª—ã–µ —Å–≤–µ—Ç–ª—ã–µ).\n",
        "multinoise = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Structure\n",
        "#@markdown LoRA - —ç—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ç–∏–ø, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ü–µ–ª–µ–π. LoCon —Ö–æ—Ä–æ—à —Å–æ —Å—Ç–∏–ª—è–º–∏ –∏—Å–∫—É—Å—Å—Ç–≤–∞, —Ç–∞–∫ –∫–∞–∫ –∏–º–µ–µ—Ç –±–æ–ª—å—à–µ —Å–ª–æ–µ–≤, —á—Ç–æ–±—ã –∏–∑—É—á–∏—Ç—å –±–æ–ª—å—à–µ –∞—Å–ø–µ–∫—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
        "lora_type = \"LoCon\" #@param [\"LoRA\", \"LoCon\", \"LoHa\"]\n",
        "\n",
        "#@markdown –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è XL –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫:\n",
        "\n",
        "#@markdown | type | network_dim | network_alpha | conv_dim | conv_alpha |\n",
        "#@markdown | :---: | :---: | :---: | :---: | :---: |\n",
        "#@markdown | Regular LoRA | 8 | 4 |   |   |\n",
        "#@markdown | Style LoCon | 16 | 8 | 16 | 8 |\n",
        "\n",
        "#@markdown –ë–æ–ª—å—à–∏–π dim –æ–∑–Ω–∞—á–∞–µ—Ç –±–æ–ª—å—à—É—é LoRA, –æ–Ω–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –±–æ–ª—å—à–µ –Ω–µ –≤—Å–µ–≥–¥–∞ –ª—É—á—à–µ.\n",
        "network_dim = 32 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "network_alpha = 32 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "#@markdown –°–ª–µ–¥—É—é—â–∏–µ –¥–≤–∞ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —Å–ª–æ—è–º LoCon.\n",
        "conv_dim = 32 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "conv_alpha = 32 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "\n",
        "network_module = \"networks.lora\"\n",
        "network_args = None\n",
        "if lora_type.lower() == \"locon\":\n",
        "  network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "\n",
        "if lora_type.lower() == \"loha\":\n",
        "  network_module = \"networks.loha\"\n",
        "  network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
        "\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Training\n",
        "#@markdown –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —ç—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Kaggle.\n",
        "#@markdown\n",
        "#@markdown –ë–æ–ª—å—à–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —á–∞—Å—Ç–æ –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏.\n",
        "train_batch_size = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "#@markdown –Ø –Ω–µ –Ω–∞—à–µ–ª —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É sdpa –∏ xformers.\n",
        "cross_attention = \"sdpa\" #@param [\"sdpa\", \"xformers\"]\n",
        "#@markdown –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `full fp16` –¥–ª—è –Ω–∞–∏–º–µ–Ω—å—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏. –û–ø—Ü–∏–∏ `bf16` –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º —É—Ä–æ–≤–Ω–µ GPU.<p>\n",
        "#@markdown LoRA –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é, –Ω–æ –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ fp16 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏.\n",
        "precision = \"full fp16\" #@param [\"float\", \"full fp16\", \"full bf16\", \"mixed fp16\", \"mixed bf16\"]\n",
        "#@markdown –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –Ω–∞ –¥–∏—Å–∫ –¥–æ–±–∞–≤–∏—Ç —Ñ–∞–π–ª —Ä–∞–∑–º–µ—Ä–æ–º 250 –ö–ë —Ä—è–¥–æ–º —Å –∫–∞–∂–¥—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º, –Ω–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏.\n",
        "cache_latents = True #@param {type:\"boolean\"}\n",
        "cache_latents_to_drive = False #@param {type:\"boolean\"}\n", # Google Drive –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ Kaggle
        "#@markdown –°–ª–µ–¥—É—é—â–∞—è –æ–ø—Ü–∏—è –æ—Ç–∫–ª—é—á–∏—Ç shuffle_tags –∏ –æ—Ç–∫–ª—é—á–∏—Ç –æ–±—É—á–µ–Ω–∏–µ text encoder.\n",
        "cache_text_encoder_outputs  = False  # @param {type:\"boolean\"}\n",
        "\n",
        "mixed_precision = \"no\"\n",
        "if \"fp16\" in precision:\n",
        "  mixed_precision = \"fp16\"\n",
        "elif \"bf16\" in precision:\n",
        "  mixed_precision = \"bf16\"\n",
        "full_precision = \"full\" in precision\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Advanced\n",
        "#@markdown –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä - —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. AdamW8bit —è–≤–ª—è–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –∏ –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ Prodigy —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–∑-–∑–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–µ–Ω—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤, –∞ —Ç–∞–∫–∂–µ –ª—É—á—à–∞—è —Ä–∞–±–æ—Ç–∞ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö.\n",
        "optimizer = \"Prodigy\" #@param [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\", \"Came\"]\n",
        "#@markdown –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è AdamW8bit: `weight_decay=0.1 betas=[0.9,0.99]`<p>\n",
        "#@markdown –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è Prodigy: `decouple=True weight_decay=0.01 betas=[0.9,0.999] d_coef=2 use_bias_correction=True safeguard_warmup=True slice_p=11`<p>\n",
        "#@markdown –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è AdaFactor: `scale_parameter=False relative_step=False warmup_init=False`<p>\n",
        "#@markdown –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è Came: `weight_decay=0.04`<p>\n",
        "#@markdown –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã Dadapt –∏–ª–∏ Prodigy –∏ –æ—Ç–º–µ—á–µ–Ω —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ñ–ª–∞–∂–æ–∫, —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç –ª—é–±—ã–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:<p>\n",
        "#@markdown `unet_lr=0.75`, `text_encoder_lr=0.75`, `network_alpha=network_dim`, `full_precision=False`<p>\n",
        "recommended_values = True #@param {type:\"boolean\"}\n",
        "#@markdown –í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏ (–Ω–µ –∑–∞–ø—è—Ç—ã–º–∏). –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ñ–ª–∞–∂–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω.\n",
        "optimizer_args = \"\" #@param {type:\"string\"}\n",
        "optimizer_args = [a.strip() for a in optimizer_args.split(' ') if a]\n",
        "\n",
        "if recommended_values:\n",
        "  if any(opt in optimizer.lower() for opt in [\"dadapt\", \"prodigy\"]):\n",
        "    unet_lr = 0.75\n",
        "    text_encoder_lr = 0.75\n",
        "    network_alpha = network_dim\n",
        "    full_precision = False\n",
        "  if optimizer == \"Prodigy\":\n",
        "    optimizer_args = [\"decouple=True\", \"weight_decay=0.01\", \"betas=[0.9,0.999]\", \"d_coef=2\", \"use_bias_correction=True\", \"safeguard_warmup=True\", \"slice_p=11\"]\n",
        "  elif optimizer == \"AdamW8bit\":\n",
        "    optimizer_args = [\"weight_decay=0.1\", \"betas=[0.9,0.99]\"]\n",
        "  elif optimizer == \"AdaFactor\":\n",
        "    optimizer_args = [\"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\"]\n",
        "  elif optimizer == \"Came\":\n",
        "    optimizer_args = [\"weight_decay=0.04\"]\n",
        "\n",
        "if optimizer == \"Came\":\n",
        "  optimizer = \"LoraEasyCustomOptimizer.came.CAME\"\n",
        "\n",
        "lr_scheduler_type = None\n",
        "lr_scheduler_args = None\n",
        "lr_scheduler_num_cycles = lr_scheduler_number\n",
        "lr_scheduler_power = lr_scheduler_number\n",
        "\n",
        "if \"rex\" in lr_scheduler:\n",
        "  lr_scheduler = \"cosine\"\n",
        "  lr_scheduler_type = \"LoraEasyCustomOptimizer.RexAnnealingWarmRestarts.RexAnnealingWarmRestarts\"\n",
        "  lr_scheduler_args = [\"min_lr=1e-9\", \"gamma=0.9\", \"d=0.9\"]\n",
        "\n",
        "# Misc\n",
        "seed = 42\n",
        "gradient_accumulation_steps = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "bucket_reso_steps = 64\n",
        "min_bucket_reso = 256\n",
        "max_bucket_reso = 4096\n",
        "\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Ready\n",
        "#@markdown –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —ç—Ç—É —è—á–µ–π–∫—É, —á—Ç–æ–±—ã –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å —Å–≤–æ—é LoRA. –£–¥–∞—á–∏! <p>\n",
        "\n",
        "\n",
        "# üë©‚Äçüíª Cool code goes here\n",
        "\n",
        "root_dir = \"/kaggle/working\"\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: Kaggle working directory
        "trainer_dir = os.path.join(root_dir, \"trainer\")\n",
        "kohya_dir = os.path.join(trainer_dir, \"sd_scripts\")\n",
        "\n",
        "venv_python = os.path.join(kohya_dir, \"venv/bin/python\")\n",
        "venv_pip = os.path.join(kohya_dir, \"venv/bin/pip\")\n",
        "train_network = os.path.join(kohya_dir, \"sdxl_train_network.py\")\n",
        "\n",
        "if \"/Loras\" in folder_structure:\n",
        "  main_dir      = os.path.join(root_dir, \"loras\") # –ò–∑–º–µ–Ω–µ–Ω–æ: Kaggle working directory
        "  log_folder    = os.path.join(main_dir, \"_logs\")\n",
        "  config_folder = os.path.join(main_dir, project_name)\n",
        "  images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
        "  output_folder = os.path.join(main_dir, project_name, \"output\")\n",
        "else:\n",
        "  main_dir      = os.path.join(root_dir, \"lora_training\") # –ò–∑–º–µ–Ω–µ–Ω–æ: Kaggle working directory
        "  images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "  output_folder = os.path.join(main_dir, \"output\", project_name)\n",
        "  config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "  log_folder    = os.path.join(main_dir, \"log\")\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "\n",
        "\n",
        "def install_trainer():\n",
        "  !apt -y update -qq\n",
        "  !apt install -y python3.10-venv aria2 -qq\n",
        "  !{venv_pip} install numpy==1.26.4\n",
        "  !git clone https://github.com/klinok64/LoRA_Easy_Training_scripts_Backend {trainer_dir}\n",
        "  !chmod 755 /kaggle/working/trainer/colab_install.sh # –ò–∑–º–µ–Ω–µ–Ω–æ: Kaggle working directory\n",
        "  os.chdir(trainer_dir)\n",
        "  !./colab_install.sh\n", # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–∫—Ä–∏–ø—Ç colab_install.sh —Å–æ–≤–º–µ—Å—Ç–∏–º —Å Kaggle environment
        "  # %cd /content/trainer\n",
        "  # !rm -f -r  sd_scripts\n",
        "  # !git clone https://github.com/kohya-ss/sd-scripts.git -b dev\n",
        "  # !mv sd-scripts sd_scripts\n",
        "  # %cd -\n",
        "\n",
        "  # fix logging\n",
        "  !{venv_pip} uninstall -y rich\n",
        "\n",
        "  # patch kohya\n",
        "  os.chdir(kohya_dir)\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # fix truncated jpegs error\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # make epoch names shorter\n",
        "    !sed -i 's/\".\" + args.save_model_as)/\"-{:02d}.\".format(num_train_epochs) + args.save_model_as)/g' train_network.py # name of the last epoch will match the rest\n",
        "  if FIX_DIFFUSERS:\n",
        "    deprecation_utils = os.path.join(kohya_dir, \"venv/lib/python3.10/site-packages/diffusers/utils/deprecation_utils.py\")\n",
        "    !sed -i 's/if version.parse/if False:#/g' {deprecation_utils}\n",
        "  if wandb_key:\n",
        "    !sed -i 's/accelerator.log(logs, step=epoch + 1)//g' train_network.py  # fix warning\n",
        "    !sed -i 's/accelerator.log(logs, step=epoch + 1)//g' sdxl_train.py  # fix warning\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "  os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "  os.chdir(root_dir)\n",
        "\n",
        "\n",
        "def validate_dataset():\n",
        "  global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, model_url\n",
        "  supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "  if model_url.startswith(\"/content/drive/\") and not os.path.exists(model_url): # –ò–∑–º–µ–Ω–µ–Ω–æ: Google Drive paths –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        "    print(\"üí• Error: The custom training model you specified was not found in your Google Drive.\") # –ò–∑–º–µ–Ω–µ–Ω–æ: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è Kaggle
        "    print(\"üí• Error: In Kaggle, please use downloadable URLs for custom models.\") # –î–æ–±–∞–≤–ª–µ–Ω–æ: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π Kaggle
        "    return\n",
        "\n",
        "  print(\"\\nüíø Checking dataset...\")\n",
        "  if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "    print(\"üí• Error: Please choose a valid project name.\")\n",
        "    return\n",
        "\n",
        "  # Find the folders and files\n",
        "  if custom_dataset:\n",
        "    try:\n",
        "      datconf = toml.loads(custom_dataset)\n",
        "      datasets = [d for d in datconf[\"datasets\"][0][\"subsets\"]]\n",
        "    except:\n",
        "      print(f\"üí• Error: Your custom dataset config is invalid or contains an error! Please check the original template.\") #  –ò–∑–º–µ–Ω–µ–Ω–æ: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è Kaggle
        "      return\n",
        "    reg = [d.get(\"image_dir\") for d in datasets if d.get(\"is_reg\", False)]\n",
        "    datasets_dict = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datasets}\n",
        "    folders = datasets_dict.keys()\n",
        "    files = [f for folder in folders for f in os.listdir(folder)]\n",
        "    images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets_dict[folder]) for folder in folders}\n",
        "  else:\n",
        "    reg = []\n",
        "    folders = [images_folder]\n",
        "    files = os.listdir(images_folder)\n",
        "    images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
        "\n",
        "  # Validation - –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —Ç–∞–∫ –∫–∞–∫ –ø—É—Ç–∏ –∫ Google Drive –º–æ–≥—É—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ Kaggle environment
        "  # for folder in folders:\n",
        "  #   if not os.path.exists(folder):\n",
        "  #     print(f\"üí• Error: The folder {folder.replace('/content/drive/', '')} doesn't exist.\")\n",
        "  #     return\n",
        "  # for folder, (img, rep) in images_repeats.items():\n",
        "  #   if not img:\n",
        "  #     print(f\"üí• Error: Your {folder.replace('/content/drive/', '')} folder is empty.\")\n",
        "  #     return\n",
        "  # test_files = []\n",
        "  # for f in files:\n",
        "  #   if not f.lower().endswith((caption_extension, \".npz\")) and not f.lower().endswith(supported_types):\n",
        "  #     print(f\"üí• Error: Invalid file in dataset: \\\"{f}\\\". Aborting.\")\n",
        "  #     return\n",
        "  #   for ff in test_files:\n",
        "  #     if f.endswith(supported_types) and ff.endswith(supported_types) \\\n",
        "  #         and os.path.splitext(f)[0] == os.path.splitext(ff)[0]:\n",
        "  #       print(f\"üí• Error: The files {f} and {ff} cannot have the same name. Aborting.\")\n",
        "  #       return\n",
        "  #   test_files.append(f)\n",
        "\n",
        "  if caption_extension and not [txt for txt in files if txt.lower().endswith(caption_extension)]:\n",
        "    caption_extension = \"\"\n",
        "  if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "    print(f\"üí• Error: Invalid path to existing Lora. Example: /kaggle/working/loras/example.safetensors\") # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle
        "    return\n",
        "\n",
        "  # Show estimations to the user\n",
        "\n",
        "  pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
        "  steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
        "  total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
        "  estimated_epochs = int(total_steps/steps_per_epoch)\n",
        "  lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
        "\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    print(\"üìÅ\"+folder.replace(\"/kaggle/working/\", \"\") + (\" (Regularization)\" if folder in reg else \"\")) # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—É—Ç—å –¥–ª—è Kaggle
        "    print(f\"üìà Found {img} images with {rep} repeats, equaling {img*rep} steps.\")\n",
        "  print(f\"üìâ Divide {pre_steps_per_epoch} steps by {train_batch_size} batch size to get {steps_per_epoch} steps per epoch.\")\n",
        "  if max_train_epochs:\n",
        "    print(f\"üîÆ There will be {max_train_epochs} epochs, for around {total_steps} total training steps.\")\n",
        "  else:\n",
        "    print(f\"üîÆ There will be {total_steps} steps, divided into {estimated_epochs} epochs and then some.\")\n",
        "\n",
        "  if total_steps > 15000:\n",
        "    print(\"üí• Error: Your total steps are too high. You probably made a mistake. Aborting...\")\n",
        "    return\n",
        "\n",
        "  return True\n",
        "\n",
        "\n",
        "def create_config():\n",
        "  global dataset_config_file, config_file, model_file\n",
        "\n",
        "  if override_config_file:\n",
        "    config_file = override_config_file\n",
        "    print(f\"\\n‚≠ï Using custom config file {config_file}\")\n",
        "  else:\n",
        "    config_dict = {\n",
        "      \"network_arguments\": {\n",
        "        \"unet_lr\": unet_lr,\n",
        "        \"text_encoder_lr\": text_encoder_lr if not cache_text_encoder_outputs else 0,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": text_encoder_lr == 0 or cache_text_encoder_outputs,\n",
        "        \"network_weights\": continue_from_lora or None\n",
        "      },\n",
        "      \"optimizer_arguments\": {\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_scheduler_type\": lr_scheduler_type,\n",
        "        \"lr_scheduler_args\": lr_scheduler_args,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler not in (\"cosine\", \"constant\") else None,\n",
        "        \"optimizer_type\": optimizer,\n",
        "        \"optimizer_args\": optimizer_args or None,\n",
        "        \"loss_type\": \"l2\",\n",
        "        \"max_grad_norm\": 1.0,\n",
        "      },\n",
        "      \"training_arguments\": {\n",
        "        \"lowram\": LOWRAM,\n",
        "        \"pretrained_model_name_or_path\": model_file,\n",
        "        \"vae\": vae_file,\n",
        "        \"max_train_steps\": max_train_steps,\n",
        "        \"max_train_epochs\": max_train_epochs,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"seed\": seed,\n",
        "        \"max_token_length\": 225,\n",
        "        \"xformers\": cross_attention == \"xformers\",\n",
        "        \"sdpa\": cross_attention == \"sdpa\",\n",
        "        \"min_snr_gamma\": min_snr_gamma if min_snr_gamma_enabled else None,\n",
        "        \"ip_noise_gamma\": ip_noise_gamma if ip_noise_gamma_enabled else None,\n",
        "        \"no_half_vae\": True,\n",
        "        \"gradient_checkpointing\": True,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "        \"max_data_loader_n_workers\": 1,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"mixed_precision\": mixed_precision,\n",
        "        \"full_fp16\": mixed_precision == \"fp16\" and full_precision,\n",
        "        \"full_bf16\": mixed_precision == \"bf16\" and full_precision,\n",
        "        \"cache_latents\": cache_latents,\n",
        "        \"cache_latents_to_disk\": cache_latents_to_drive,\n",
        "        \"cache_text_encoder_outputs\": cache_text_encoder_outputs,\n",
        "        \"min_timestep\": 0,\n",
        "        \"max_timestep\": 1000,\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "        \"multires_noise_iterations\": 6 if multinoise else None,\n",
        "        \"multires_noise_discount\": 0.3 if multinoise else None,\n",
        "        \"v_parameterization\": vpred or None,\n",
        "        \"scale_v_pred_loss_like_noise_pred\": vpred or None,\n",
        "        \"zero_terminal_snr\": vpred or None,\n",
        "      },\n",
        "      \"saving_arguments\": {\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"save_model_as\": \"safetensors\",\n",
        "        \"save_every_n_epochs\": save_every_n_epochs,\n",
        "        \"save_every_n_steps\": save_every_n_steps,\n",
        "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "        \"output_name\": project_name,\n",
        "        \"output_dir\": output_folder,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"logging_dir\": log_folder,\n",
        "        \"wandb_api_key\": wandb_key or None,\n",
        "        \"log_with\": \"wandb\" if wandb_key else None,\n",
        "      }\n",
        "    }\n",
        "\n",
        "    for key in config_dict:\n",
        "      if isinstance(config_dict[key], dict):\n",
        "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(config_dict))\n",
        "    print(f\"\\nüìÑ Config saved to {config_file}\")\n",
        "\n",
        "  if override_dataset_config_file:\n",
        "    dataset_config_file = override_dataset_config_file\n",
        "    print(f\"‚≠ï Using custom dataset config file {dataset_config_file}\")\n",
        "  else:\n",
        "    dataset_config_dict = {\n",
        "      \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": shuffle_caption and not cache_text_encoder_outputs,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"flip_aug\": False,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_no_upscale\": False,\n",
        "        \"bucket_reso_steps\": bucket_reso_steps,\n",
        "        \"min_bucket_reso\": min_bucket_reso,\n",
        "        \"max_bucket_reso\": max_bucket_reso,\n",
        "      },\n",
        "      \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "        {\n",
        "          \"subsets\": [\n",
        "            {\n",
        "              \"num_repeats\": num_repeats,\n",
        "              \"image_dir\": images_folder,\n",
        "              \"class_tokens\": None if caption_extension else project_name\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    for key in dataset_config_dict:\n",
        "      if isinstance(dataset_config_dict[key], dict):\n",
        "        dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(dataset_config_dict))\n",
        "    print(f\"üìÑ Dataset config saved to {dataset_config_file}\")\n",
        "\n",
        "\n",
        "def download_model():\n",
        "  global old_model_url, model_url, model_file, vae_url, vae_file\n",
        "  real_model_url = model_url  # There was a reason for having a separate variable but I forgot what it was.\n",
        "\n",
        "  if real_model_url.startswith(\"/content/drive/\"):\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: Google Drive paths –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        "    # Local model, already checked to exist\n",
        "    model_file = real_model_url\n",
        "    print(f\"üìÅ Using local model file: {model_file}\")\n",
        "    # Validation\n",
        "    if model_file.lower().endswith(\".safetensors\"):\n",
        "      from safetensors.torch import load_file as load_safetensors\n",
        "      try:\n",
        "        test = load_safetensors(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "    elif model_file.lower().endswith(\".ckpt\"):\n",
        "      from torch import load as load_ckpt\n",
        "      try:\n",
        "        test = load_ckpt(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  else:\n",
        "    # Downloadable model\n",
        "    if load_diffusers:\n",
        "      if 'huggingface.co' in real_model_url:\n",
        "          match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', real_model_url)\n",
        "          if match:\n",
        "              username = match.group(1)\n",
        "              model_name = match.group(2)\n",
        "              model_file = f\"{username}/{model_name}\"\n",
        "              from huggingface_hub import HfFileSystem\n",
        "              fs = HfFileSystem()\n",
        "              existing_folders = set(fs.ls(model_file, detail=False))\n",
        "              necessary_folders = [ \"scheduler\", \"text_encoder\", \"text_encoder_2\", \"tokenizer\", \"tokenizer_2\", \"unet\", \"vae\" ]\n",
        "              if all(f\"{model_file}/{folder}\" in existing_folders for folder in necessary_folders):\n",
        "                print(\"üçÉ Diffusers model identified.\")  # Will be handled by kohya\n",
        "                return True\n",
        "      raise ValueError(\"üí• Failed to load Diffusers model. If this model is not Diffusers, have you tried turning it off at the top of the colab?\")\n",
        "\n",
        "    # Define local filename\n",
        "    if not model_file or old_model_url and old_model_url != model_url:\n",
        "      if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "        model_file = f\"/content{real_model_url[real_model_url.rfind('/'):]}\"\n",
        "      else:\n",
        "        model_file = \"/content/downloaded_model.safetensors\"\n",
        "        if os.path.exists(model_file):\n",
        "          !rm \"{model_file}\"\n",
        "\n",
        "    # HuggingFace\n",
        "    if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", real_model_url):\n",
        "      real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "    # Civitai\n",
        "    elif m := re.search(r\"(?:https?://)?(?:www\\\\.)?civitai\\.com/models/([0-9]+)(/[A-Za-z0-9-_]+)?\", real_model_url):\n",
        "      if m.group(2):\n",
        "        model_file = f\"/content{m.group(2)}.safetensors\"\n",
        "      if m := re.search(r\"modelVersionId=([0-9]+)\", real_model_url):\n",
        "        real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "      else:\n",
        "        raise ValueError(\"üí• optional_custom_training_model contains a civitai link, but the link doesn't include a modelVersionId. You can also right click the download button to copy the direct download link.\")\n",
        "\n",
        "    # Download checkpoint\n",
        "    !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "    # Download VAE\n",
        "    if not os.path.exists(vae_file):\n",
        "      !aria2c \"{vae_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{vae_file}\"\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    if model_file.lower().endswith(\".safetensors\"):\n",
        "      from safetensors.torch import load_file as load_safetensors\n",
        "      try:\n",
        "        test = load_safetensors(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "        !mv \"{model_file}\" \"{new_model_file}\"\n",
        "        model_file = new_model_file\n",
        "        print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "    if model_file.lower().endswith(\".ckpt\"):\n",
        "      from torch import load as load_ckpt\n",
        "      try:\n",
        "        test = load_ckpt(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "\n",
        "  return True\n",
        "\n",
        "\n",
        "def calculate_rex_steps():\n",
        "    # https://github.com/derrian-distro/LoRA_Easy_Training_scripts_Backend/blob/c34084b0435e6e19bb7a01ac1ecbadd185ee8c1e/utils/validation.py#L268\n",
        "    global max_train_steps\n",
        "\n",
        "    cache_file = os.path.join(config_folder, \"rex_steps_cache.json\")  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–µ—à–∞\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ –∫–µ—à–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
        "    if os.path.exists(cache_file):\n",
        "        try:\n",
        "            with open(cache_file, \"r\") as f:\n",
        "                cached_data = json.load(f)\n",
        "                if cached_data.get(\"max_train_steps\") == max_train_steps and \\\n",
        "                   cached_data.get(\"max_train_epochs\") == max_train_epochs and \\\n",
        "                   cached_data.get(\"train_batch_size\") == train_batch_size and \\\n",
        "                   cached_data.get(\"lr_scheduler_num_cycles\") == lr_scheduler_num_cycles and \\\n",
        "                   cached_data.get(\"lr_warmup_ratio\") == lr_warmup_ratio and \\\n",
        "                   cached_data.get(\"dataset_config_file\") == dataset_config_file:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "\n",
        "                    calculated_max_steps = cached_data[\"calculated_max_steps\"]\n",
        "                    print(\"ü§î Rex steps loaded from cache\")\n",
        "\n",
        "                    cycle_steps = calculated_max_steps // (lr_scheduler_num_cycles or 1)\n",
        "                    print(f\"  cycle steps: {cycle_steps}\")\n",
        "                    lr_scheduler_args.append(f\"first_cycle_max_steps={cycle_steps}\")\n",
        "\n",
        "                    warmup_steps = round(calculated_max_steps * lr_warmup_ratio) // (lr_scheduler_num_cycles or 1)\n",
        "                    if warmup_steps > 0:\n",
        "                        print(f\"  warmup steps: {warmup_steps}\")\n",
        "                        lr_scheduler_args.append(f\"warmup_steps={warmup_steps}\")\n",
        "\n",
        "                    return\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading cache: {e}\")\n",
        "\n",
        "\n",
        "    print(\"\\nü§î Calculating Rex steps\")\n",
        "    if max_train_steps:\n",
        "        calculated_max_steps = max_train_steps\n",
        "    else:\n",
        "        from library.train_util import BucketManager\n",
        "        from PIL import Image\n",
        "        from pathlib import Path\n",
        "        import math\n",
        "\n",
        "        with open(dataset_config_file, \"r\") as f:\n",
        "            subsets = toml.load(f)[\"datasets\"][0][\"subsets\"]\n",
        "\n",
        "        supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\"]\n",
        "        res = (resolution, resolution)\n",
        "        bucketManager = BucketManager(False, res, min_bucket_reso, max_bucket_reso, bucket_reso_steps)\n",
        "        bucketManager.make_buckets()\n",
        "        for subset in subsets:\n",
        "            for image in Path(subset[\"image_dir\"]).iterdir():\n",
        "                if image.suffix not in supported_types:\n",
        "                    continue\n",
        "                with Image.open(image) as img:\n",
        "                    bucket_reso, _, _ = bucketManager.select_bucket(img.width, img.height)\n",
        "                    for _ in range(subset[\"num_repeats\"]):\n",
        "                        bucketManager.add_image(bucket_reso, image)\n",
        "        steps_before_acc = sum(math.ceil(len(bucket) / train_batch_size) for bucket in bucketManager.buckets)\n",
        "        calculated_max_steps = math.ceil(steps_before_acc / gradient_accumulation_steps) * max_train_epochs\n",
        "        del bucketManager\n",
        "\n",
        "    cycle_steps = calculated_max_steps // (lr_scheduler_num_cycles or 1)\n",
        "    print(f\"  cycle steps: {cycle_steps}\")\n",
        "    lr_scheduler_args.append(f\"first_cycle_max_steps={cycle_steps}\")\n",
        "\n",
        "    warmup_steps = round(calculated_max_steps * lr_warmup_ratio) // (lr_scheduler_num_cycles or 1)\n",
        "    if warmup_steps > 0:\n",
        "        print(f\"  warmup steps: {warmup_steps}\")\n",
        "        lr_scheduler_args.append(f\"warmup_steps={warmup_steps}\")\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —Ñ–∞–π–ª –∫–µ—à–∞\n",
        "    with open(cache_file, \"w\") as f:\n",
        "        json.dump({\"calculated_max_steps\": calculated_max_steps,\n",
        "                   \"max_train_steps\": max_train_steps,\n",
        "                   \"max_train_epochs\": max_train_epochs,\n",
        "                   \"train_batch_size\": train_batch_size,\n",
        "                   \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles,\n",
        "                   \"lr_warmup_ratio\": lr_warmup_ratio,\n",
        "                   \"dataset_config_file\": dataset_config_file}, f)  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "    print(\"ü§î Rex steps calculated and cached\")\n",
        "\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed, images_folder # –î–æ–±–∞–≤–ª–µ–Ω–æ: images_folder –≤ globals\n",
        "\n",
        "  # Google Drive mount removed for Kaggle\n",
        "  # if not os.path.exists('/content/drive'):\n",
        "  #   from google.colab import drive\n",
        "  #   print(\"üìÇ Connecting to Google Drive...\")\n",
        "  #   drive.mount('/content/drive')\n",
        "\n",
        "  # Adjust image folder path for Kaggle input - assumes dataset is in /kaggle/input\n",
        "  if \"/Loras\" in folder_structure:\n",
        "      if not custom_dataset:\n", # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        "          images_folder = os.path.join(\"/kaggle/input\", project_name, \"dataset\") #  –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ Kaggle Dataset –∏ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è project_name
        "  else:\n",
        "      if not custom_dataset:\n", # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        "          images_folder = os.path.join(\"/kaggle/input\", project_name) #  –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ Kaggle Dataset –∏ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è project_name\n",
        "          if not os.path.exists(images_folder): # Fallback, –µ—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–º–µ–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É 'datasets/project_name'
        "              images_folder = os.path.join(\"/kaggle/input\", \"datasets\", project_name)\n",
        "\n",
        "  for dir in (main_dir, trainer_dir, log_folder, images_folder, output_folder, config_folder):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  if not validate_dataset():\n",
        "    return\n",
        "\n",
        "  if not dependencies_installed:\n",
        "    print(\"\\nüè≠ Installing trainer...\\n\")\n",
        "    t0 = time()\n",
        "    install_trainer()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\n‚úÖ Installation finished in {int(t1-t0)} seconds.\")\n",
        "  else:\n",
        "    print(\"\\n‚úÖ Dependencies already installed.\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\nüîÑ Getting model...\")\n",
        "    if not download_model():\n",
        "      print(\"\\nüí• Error: The model you specified is invalid or corrupted.\"\n",
        "            \"\\nIf you're using an URL, please check that the model is accessible without being logged in.\"\n",
        "            \"\\nYou can try civitai or huggingface URLs.\") # –ò–∑–º–µ–Ω–µ–Ω–æ: –£–±—Ä–∞–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ Google Drive
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\nüîÑ Model already downloaded.\\n\")\n",
        "\n",
        "  if lr_scheduler_type:\n",
        "    create_config()\n",
        "    os.chdir(kohya_dir)\n",
        "    calculate_rex_steps()\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "  create_config()\n",
        "\n",
        "  print(\"\\n‚≠ê Starting trainer...\\n\")\n",
        "\n",
        "  os.chdir(kohya_dir)\n",
        "  !{venv_python} {train_network} --config_file={config_file} --dataset_config={dataset_config_file} --debiased_estimation_loss\n",
        "  os.chdir(root_dir)\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    display(Markdown(\"### ‚úÖ Done! [Go download your Lora from Kaggle Working directory](/kaggle/working)\\n\"\ # –ò–∑–º–µ–Ω–µ–Ω–æ: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ Kaggle
        "                     \"### There will be several files, you should try the latest version (the file with the largest number next to it)\"))\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{venv_pip} install numpy==1.26.4"
      ],
      "metadata": {
        "id": "9EzkMv0dwV81",
        "outputId": "53ceceef-d4ea-4cd0-ffa6-0f24ade05d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBMUJ7BuvNcn"
      },
      "source": [
        "## *Ô∏è‚É£ Extras\n",
        "\n",
        "–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—É—á–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4916Eu1tb9"
      },
      "source": [
        "### üìö Multiple folders in dataset\n",
        "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω —à–∞–±–ª–æ–Ω, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞–ø–æ–∫ –≤ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –í—ã –¥–æ–ª–∂–Ω—ã —É–∫–∞–∑–∞—Ç—å –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–∏ –∏ –º–æ–∂–µ—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ –Ω–∏—Ö. –ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø–∞–ø–æ–∫, –ø—Ä–æ—Å—Ç–æ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Ä–∞–∑–¥–µ–ª—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å `[[datasets.subsets]]`.\n",
        "\n",
        "–ü—Ä–∏ –≤–∫–ª—é—á–µ–Ω–∏–∏ —ç—Ç–æ–π –æ–ø—Ü–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —è—á–µ–π–∫–µ, –±—É–¥–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è, –∞ —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –æ—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∏–º–µ–Ω–µ–º –ø—Ä–æ–µ–∫—Ç–∞.\n",
        "\n",
        "–í—ã –º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å –æ–¥–Ω—É –∏–∑ –Ω–∏—Ö –ø–∞–ø–∫–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, –¥–æ–±–∞–≤–∏–≤ `is_reg = true`  \n",
        "–í—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–Ω—ã–µ `keep_tokens`, `flip_aug` –∏ —Ç. –¥."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y037lagnJWmn"
      },
      "source": [
        "custom_dataset = \"\"\"\n",
        "[[datasets]]\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/1\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 1\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/2\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 2\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/3\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 3\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/4\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 4\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/5\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 5\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/kaggle/working/loras/hypnohub512/dataset/6\" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle\n",
        "num_repeats = 1\n",
        "keep_tokens = 6\n",
        "\n",
        "\"\"\""
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W84Jxf-U2TIU"
      },
      "source": [
        "custom_dataset = None"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "WDjkp4scvPgE",
        "outputId": "78189c05-c4dc-4779-a27a-defa0828cf00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Unzip dataset\n",
        "#@markdown –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ Kaggle Dataset –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –ø–æ—ç—Ç–æ–º—É –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å zip-–∞—Ä—Ö–∏–≤, –µ—Å–ª–∏ –≤–∞—à –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ.\n",
        "#@markdown **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à zip-—Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Kaggle Datasets.**\n",
        "zip = \"/kaggle/input/your-dataset-zip-name/hypnohub512.zip\" #@param {type:\"string\"}\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—É—Ç—å –∫ zip-—Ñ–∞–π–ª—É –≤ Kaggle Dataset
        "extract_to = \"/kaggle/working/loras/hypnohub512/\" #@param {type:\"string\"}\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: Kaggle working directory
        "\n",
        "import os, zipfile\n",
        "\n",
        "# Google Drive mount removed for Kaggle\n",
        "# if not os.path.exists('/content/drive'):\n",
        "#   from google.colab import drive\n",
        "#   print(\"üìÇ Connecting to Google Drive...\")\n",
        "#   drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "aKWlpsG0jrX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b23acf-cbdd-41aa-ebe0-c89872d23208"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Count datasets\n",
        "#@markdown Kaggle –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ —Å—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ –ø–æ–∫–∞–∂–µ—Ç –≤–∞–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö –∏ –ø–æ–¥–ø–∞–ø–∫–∞—Ö.\n",
        "folder = \"/kaggle/input\" #@param {type:\"string\"}\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ Kaggle input
        "\n",
        "import os\n",
        "# Google Drive mount removed for Kaggle\n",
        "# from google.colab import drive\n",
        "\n",
        "# if not os.path.exists('/content/drive'):\n",
        "#     print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "#     drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "-cnM6xM_E6Jx"
      },
      "outputs": [],
      "source": [
        "#@markdown ### ‚Ü™Ô∏è Continue\n",
        "\n",
        "#@markdown –ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –≤ –≤–∞—à–µ–π —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Kaggle, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª LoRA –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è.<p>\n",
        "#@markdown **–í–Ω–∏–º–∞–Ω–∏–µ:** –≠—Ç–æ –Ω–µ —Ç–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ –∏ –æ–¥–Ω–∞ –¥–ª–∏–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –æ–±—É—á–µ–Ω–∏—è. –≠–ø–æ—Ö–∏ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –Ω—É–ª—è, –∏ —ç—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ö—É–¥—à–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º.\n",
        "continue_from_lora = \"/kaggle/working/loras/hypnohub512/output/1234/hypnohub512-step00000600.safetensors\" #@param {type:\"string\"}\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–∏–º–µ—Ä –ø—É—Ç–∏ –¥–ª—è Kaggle
        "if continue_from_lora and not continue_from_lora.startswith(\"/kaggle/working\"):\n", # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏ –¥–ª—è Kaggle working directory
        "  import os\n",
        "  continue_from_lora = os.path.join(\"/kaggle/working\", continue_from_lora)\n" # –ò–∑–º–µ–Ω–µ–Ω–æ: –ü—É—Ç—å –¥–ª—è Kaggle working directory
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcTjh07x90Ro"
      },
      "source": [
        "# üìà Plot training results\n",
        "–í—ã –º–æ–∂–µ—Ç–µ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Ç—Ä–µ–Ω–µ—Ä–∞. –í–∞–º —ç—Ç–æ –Ω–µ –Ω—É–∂–Ω–æ, –µ—Å–ª–∏ –≤—ã –Ω–µ –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ.  \n",
        "–ü–µ—Ä–≤–∞—è —è—á–µ–π–∫–∞ –Ω–∏–∂–µ –º–æ–∂–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –≤–∞—à–∏ –∂—É—Ä–Ω–∞–ª—ã. –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—Ç–æ—Ä—É—é —è—á–µ–π–∫—É, –ø–æ–∫–∞ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∑—è—Ç—Å—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_TRI3eX90Rp"
      },
      "source": [
        "# %load_ext tensorboard # Tensorboard magic command –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Kaggle notebooks\n",
        "# %tensorboard --logdir={log_folder}/ # Tensorboard magic command –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Kaggle notebooks\n",
        "print(\"TensorBoard –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –≤ Kaggle Notebooks. –í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Kaggle API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–≥–æ–≤ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Ö –ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å WandB.\") # –î–æ–±–∞–≤–ª–µ–Ω–æ: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ TensorBoard –≤ Kaggle"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rM5SLq990Rp"
      },
      "source": [
        "# from tensorboard import notebook # Tensorboard notebook display –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Kaggle notebooks\n",
        "# notebook.display(port=6006, height=800) # Tensorboard notebook display –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Kaggle notebooks\n",
        "print(\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è TensorBoard –≤ Kaggle Notebooks –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è WandB –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–≥–æ–≤ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞.\") # –î–æ–±–∞–≤–ª–µ–Ω–æ: –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ TensorBoard –≤ Kaggle"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}